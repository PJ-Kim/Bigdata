BIG Data with AWS RDS and PySpark

Using a dataset with 1.5 million row; with over 40 datasets representing Amazon product reviews
  1. Perform ETL on this dataset completely in the cloud
  2. Upload a DataFrame to an RDS instance
  3. Use PySpark to perform statistical analysis of the selected data

